{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1498711",
   "metadata": {},
   "source": [
    "Modèle de LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de6aae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mistralai import ChatMistralAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "#Chargement des variables d'environnement\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"MISTRAL_API_KEY\"] = os.getenv(\"MISTRAL_API_KEY\")\n",
    "\n",
    "#Chargement des modeles\n",
    "model_codestral = ChatMistralAI(model=\"codestral-latest\", temperature = 0)\n",
    "model_mistral_medium = ChatMistralAI(model=\"mistral-medium-latest\", temperature = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4190f9b4",
   "metadata": {},
   "source": [
    "**Agent**\n",
    "\n",
    "Interface agent définissant la forme d'un agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a9572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from OrderState import OrderState\n",
    "\n",
    "class Agent(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def interaction(self, State : OrderState) -> OrderState:\n",
    "        pass\n",
    "\n",
    "    def obtenir_tokens(self, data_caracs):\n",
    "        return (data_caracs.usage_metadata['input_tokens'], data_caracs.usage_metadata['output_tokens'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c850c8",
   "metadata": {},
   "source": [
    "**Créateur de tâche**\n",
    "\n",
    "Créateur de tâche. Analyse une question pour la décomposer en liste de tâches à effectuer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e8b751",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Informations qu'il est possible d'obtenir depuis la base de donnée\n",
    "INFORMATIONS_POSSIBLES = '''\n",
    "    - Les programmes\n",
    "    - Les cycles\n",
    "    - Les outils\n",
    "    - Les alarmes\n",
    "'''\n",
    "#Traitements qu'il est possible de faire à partir des données de la base de donnée\n",
    "TRAITEMENTS_POSSIBLES = '''\n",
    "- Trouver les occurences des éléments parmi l'information cherchée et les classer par ordre décroissant\n",
    "- Exprimer une information en fonction d'une autre information\n",
    "- Calculer la somme d'une information\n",
    "- Diviser deux valeurs\n",
    "- Filtrer une une colonne de DataFrames en fonction de critères. Avant d'utiliser ce traitement, utiliser le traitement : Exprimer une information en fonction d'une autre information\n",
    "- Afficher des informations sur un graphique\n",
    "'''\n",
    "#Documentation utile pour aider l'agent à comprendre des termes spécifiques à l'entreprise\n",
    "DOCUMENTATION = '''\n",
    "Comment calculer un rendement de coupe ?\n",
    "Il faut tout d'abord extraire les temps de cycle et les temps où les machines sont allumées.\n",
    "Ensuite, il faut calculer la somme des temps de cycle divisée par la somme des temps où les machines sont allumées.\n",
    "\n",
    "'''\n",
    "#Exemples d'entrées et sorties de l'agent\n",
    "EXEMPLES = '''\n",
    "Inspire toi des exemples pour élaborer tes réponses.\n",
    "En général, on filtre les dataFrames à la fin. Si tu ne le fais pas, on te débranche du DataCenter\n",
    "\n",
    "\n",
    "Exemple :\n",
    "Liste les programmes \n",
    "INFORMATION_CHERCHER = \"Trouver les programmes\"\n",
    "\n",
    "-----------------------------------------------------------------------\n",
    "\n",
    "Exemple :\n",
    "Liste les cycles \n",
    "INFORMATION_CHERCHER = \"Trouver les cycles\"\n",
    "\n",
    "-----------------------------------------------------------------------\n",
    "\n",
    "Exemple :\n",
    "Liste les outils\n",
    "INFORMATION_CHERCHER = \"Trouver les outils\"\n",
    "\n",
    "Exemple :\n",
    "Trouver les programmes en fonction de leur cycle associé.\n",
    "\n",
    "INFORMATION_CHERCHER='Trouver les programmes et les cycles' TRAITEMENT=['Exprimer les programmes en fonction de leur cycle associé']\n",
    "-----------------------------------------------------------------------\n",
    "\n",
    "Exemple :\n",
    "Trouver les <p id = 1>outils</p> utilisés dans le programme _N_OP20_AIR_SPF\n",
    "\n",
    "Explication du deuxième traitement : \n",
    "On regarde la liste des <p id = 1>outils</p> utilisés. Puis, on ne garde que les <p id = 1>outils</p> que nous voulons trouver correspondant au programme _N_OP20_AIR_SPF\n",
    "\n",
    "INFORMATION_CHERCHER = 'Trouver les programmes, les cycles, les outils et les temps de coupe' TRAITEMENT = ['<Exprimer les programmes en fonction de leur cycle associé et exprimer les outils en fonction de leur temps de coupe associé>', 'Filtrer les <p id = 1>outils</p> utilisés avec le programme _N_OP20_AIR_SPF>']\n",
    "\n",
    "-----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "Exemple :\n",
    "Repère la valeur maximum de la charge de broche.\n",
    "\n",
    "INFORMATION_CHERCHER='Trouver les valeurs de la charge de broche' TRAITEMENT=['Trouver la valeur de la broche']\n",
    "\n",
    "-----------------------------------------------------------------------\n",
    "\n",
    "Exemple :\n",
    "Chercher la température\n",
    "INFORMATION_CHERCHER = 'Chercher la température' TRAITEMENT = []\n",
    "\n",
    "-----------------------------------------------------------------------\n",
    "\n",
    "Exemple :\n",
    "Quelles sont les outils ayant dépassé deux heures de coupe cumulées ?\n",
    "INFORMATION_CHERCHER = 'Chercher les outils et les temps de coupe' TRAITEMENT = [Exprimer les outils en fonction de leur temps de coupe associé, Filtrer les outils ayant dépassé deux heures de coupe cumulées]\n",
    "\n",
    "-----------------------------------------------------------------------\n",
    "\n",
    "Exemple :\n",
    "Quelles sont les 3 alarmes les plus récurrentes ?\n",
    "\n",
    "INFORMATION_CHERCHER = \"Trouver les alarmes entre le 01/03/2025 et le 01/06/2025\" TRAITEMENT = [\"Trouver les occurences des alarmes parmi les alarmes et les classer par ordre décroissant\", \"Extraire les 3 premières occurences des alarmes\"]\n",
    "\n",
    "'''\n",
    "#Prompt donné à l'agent\n",
    "AGENT_JOB = f'''\n",
    "Tu es chargé de traiter une question pour en extraire l'information cherchée et les traitements à effectuer\n",
    "sur cette information. Exprime l'information cherchée et les traitements sous la forme d'un ordre.\n",
    "Il est possible que des traitements ne soit pas associé à une question. \n",
    "\n",
    "L'information cherchée doit toujours être demandée entre deux dates précises. \n",
    "Les informations qu'il est possible de chercher sont : {INFORMATIONS_POSSIBLES}\n",
    "\n",
    "Les traitements possibles sont : {TRAITEMENTS_POSSIBLES}\n",
    "\n",
    "Documentation : {DOCUMENTATION}\n",
    "\n",
    "Par défaut, si la liste des programmes est demandée à chercher et que des traitements sont à effectuer, il faut également demander à chercher leur cycle associé.\n",
    "Pour, les outils, il faut aussi demander leur temps de coupe associé.\n",
    "De même pour les alarmes\n",
    "Vérifie bien qu'il y a suffisamment d'informations demandées pour accomplir les traitements voulus.\n",
    "\n",
    "Information sur la base de donnée : \n",
    "Les outils utilisés sont inclus dans des temps de coupe.\n",
    "Les temps de coupe sont inclus dans des programmes\n",
    "Les programmes sont inclus dans des temps de cycles.\n",
    "\n",
    "Chaque programme est associé à un cycle.\n",
    "Chaque outil est associé à un temps de coupe.\n",
    "\n",
    "Si aucune date n'est précisé, prendre entre aujourd'hui et 90 jours avant\n",
    "\n",
    "{EXEMPLES}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c5bfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, List\n",
    "\n",
    "#Forme de la réponse voulue donnée par l'agent\n",
    "class Separation(BaseModel):\n",
    "    \"\"\"Sépare un texte pour en obtenir l'information à chercher et le traitement fait sur l'information.\n",
    "    Les données contenues dans les attributs doivent être des phrases\n",
    "    \"\"\"\n",
    "\n",
    "    INFORMATION_CHERCHER : str = Field(description = \"Information recherchée dans la base de donnée. Exprimé sous forme d'un ordre.\")\n",
    "    DESCRIPTION_IMFORMATION_CHERCHER : str = Field(description = \"Justification de INFORMATION_CHERCHER\")\n",
    "    TRAITEMENT : Optional[List[str]] = Field(default= None, description = \"Traitements faits sur les informations de la base de donnée déduit à partir de la question. Exprimé sous forme d'un ordre\")\n",
    "    DESCRIPTION_TRAITEMENT : Optional[str] = Field(default = None, description = \"Justification de TRAITEMENT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a4223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, List\n",
    "from OrderState import OrderState\n",
    "from model import model_codestral, model_mistral_medium\n",
    "from Graph_Agents.CreateurTache.CreateurTache_Prompt import AGENT_JOB\n",
    "\n",
    "from Graph_Agents.Agent import Agent\n",
    "\n",
    "from datetime import datetime\n",
    "        \n",
    "class CreateurTache(Agent):\n",
    "        \n",
    "    def __init__(self, Separation : BaseModel):\n",
    "        #Model forcé à envoyer une réponse structurée sous la forme de Separation\n",
    "        self.structured_llm = model_mistral_medium.with_structured_output(Separation, include_raw=True)\n",
    "        #Créateur de tâches \n",
    "\n",
    "    def interaction(self, state: OrderState) -> OrderState:\n",
    "        \"\"\"The chatbot itself. A wrapper around the model's own chat interface.\"\"\"\n",
    "\n",
    "        #Appel à structured_llm\n",
    "        new_output = self.structured_llm.invoke([AGENT_JOB, state['question']])\n",
    "\n",
    "        state['input_tokens'], state['output_tokens'] = self.obtenir_tokens(new_output['raw'])\n",
    "        state['prix_input_tokens'] += state['input_tokens'] * 0.4 / 10 ** 6\n",
    "        state['prix_output_tokens'] += state['output_tokens'] * 2 / 10 ** 6\n",
    "\n",
    "        state['information_chercher'] = new_output['parsed'].INFORMATION_CHERCHER\n",
    "\n",
    "        #Affichage de la réponse de structured_llm\n",
    "        print(f\"Information cherchée : {new_output['parsed'].INFORMATION_CHERCHER} \\n\")\n",
    "        print(f\"Justification : {new_output['parsed'].DESCRIPTION_IMFORMATION_CHERCHER}\")\n",
    "        \n",
    "        if hasattr(new_output['parsed'], 'TRAITEMENT') and new_output['parsed'].TRAITEMENT != None:\n",
    "            state['traitements'] = new_output['parsed'].TRAITEMENT\n",
    "\n",
    "            self.afficher_traitement(new_output['parsed'])\n",
    "        \n",
    "        else:\n",
    "            state['traitements'] = []\n",
    "\n",
    "        return state\n",
    "    \n",
    "    def afficher_traitement(self, message):\n",
    "        n = len(message.TRAITEMENT)\n",
    "        msg_traitement = \"\"\n",
    "        for i in range(n):\n",
    "            msg_traitement += f\"Traitement effectué {i + 1} : \" + message.TRAITEMENT[i] + \"\\n\"\n",
    "\n",
    "        print(msg_traitement + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0c0637",
   "metadata": {},
   "source": [
    "**Extract_docs**\n",
    "\n",
    "Agent chargé d'intéragir avec la base de donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fc675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from OrderState import OrderState\n",
    "from model import model_codestral\n",
    "\n",
    "from Graph_Agents.ExtractDocsAgent.request_format import request\n",
    "from Graph_Agents.Agent import Agent\n",
    "\n",
    "class Extract_docs_agent(Agent):\n",
    "    def __init__(self):\n",
    "        self.structured_llm = model_codestral.with_structured_output(request, include_raw = True)\n",
    "\n",
    "    def interaction(self, state: OrderState) -> OrderState:\n",
    "        \"\"\"The chatbot itself. A wrapper around the model's own chat interface.\"\"\"\n",
    "\n",
    "        #Agent chargé de formaliser sous la forme d'une requête l'information à chercher\n",
    "        # Appel du modèle structuré\n",
    "        req = self.structured_llm.invoke(state['information_chercher'])\n",
    "\n",
    "        state['input_tokens'], state['output_tokens'] = self.obtenir_tokens(req['raw'])\n",
    "        \n",
    "        state['prix_input_tokens'] += state['input_tokens'] * 0.3 / 10 ** 6\n",
    "        state['prix_output_tokens'] += state['output_tokens'] * 0.9 / 10 ** 6\n",
    "\n",
    "        # ✅ Stocker proprement\n",
    "        state['request_call'] = req['parsed']\n",
    "        state['request_call_initial'] = req['parsed']\n",
    "        print(\"➡️ Requête extraite :\", req['parsed'])\n",
    "        print(\"📦 State keys: EXTRACT_DOC\", list(state.keys()))\n",
    "        return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c469db1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from typing import Optional, List\n",
    "\n",
    "from aenum import Enum\n",
    "\n",
    "class periode(BaseModel):\n",
    "\n",
    "    type : str = Field(description= \"Type de la période\")\n",
    "    valeur : str = Field(description=\"Comment est réprésenté la période\")\n",
    "\n",
    "    date_from : str = Field(description = \"Date de début de période au format ISO 8601\")\n",
    "    date_to : str = Field(description= \"Date de fin de période au format ISO 8601\")\n",
    "\n",
    "DEBUT = 'Si la question_utilisateur contient : '\n",
    "\n",
    "class Attribut_Principal(Enum):\n",
    "    _init_ = 'value __doc__'\n",
    "\n",
    "class Attribut(Enum):\n",
    "    _init_ = 'value __doc__'\n",
    "    NOM_PROGRAMME_SELECT = \"property.nomProgrammeSelect\", DEBUT + '\"programme\" ou \"rendement de coupe\"'\n",
    "    NOM_OUTIL_BROCHE = \"property.activeToolNumber\", DEBUT + '\"outil\"'\n",
    "    POWER_X = \"property.power_X\", DEBUT + '\"outil\"'\n",
    "    POWER_Y = \"property.power_Y\", DEBUT + '\"outil\"'\n",
    "    POWER_Z = \"property.power_Z\", DEBUT + '\"outil\"'\n",
    "    POWER_SPINDLE = \"property.powerSpindle\", DEBUT + '\"coût énergétique\", ou \"puissance\"'\n",
    "    POWER_A = \"property.power_A\", DEBUT + '\"coût énergétique\"**, ou **\"puissance\"'\n",
    "    POWER_C = \"property.power_C\", DEBUT + '\"coût énergétique\", ou \"puissance\"'\n",
    "    SPINdLOAD = \"property.spindlLoad\", DEBUT + '\"charge de la broche\" ou \"couple\"'\n",
    "    ALARME = \"property.numDerniereAlarme\", DEBUT + '\"alarme\" ou \"défaut\"'\n",
    "    CYCLE = \"property.operatingTime\", DEBUT + '\"cycle\".'\n",
    "    TEMPS_DE_COUPE = \"property.cuttingTime\", DEBUT + '\"coupe\".'\n",
    "    TEMPS_BROCHE_EXT = \"property.tempBrocheExt\", DEBUT + '\"température\" ou \"chaleur\"'\n",
    "    SUM_CYCLE_TIME_NET = \"property.sumCycleTimeNet\", DEBUT + '\"rendement de coupe\"'\n",
    "\n",
    "class Machine(Enum):\n",
    "    Huron_KXFive = \"logstash-huron-k3x8f-202*\"\n",
    "    SigScan = \"sigscan\"\n",
    "\n",
    "class variable_principale(BaseModel):\n",
    "    nom : Attribut_Principal = Field(description = \"Nom de l'attribut de la variable principale parmi les énumérations\")\n",
    "    alias : str = Field(description = \"Nom de la variable\")\n",
    "    role : str = Field(description = \"Role de la variable\")\n",
    "    \n",
    "class variable(BaseModel):\n",
    "    nom : Attribut = Field(description = \"Nom de l'attribut de la variable parmi les énumérations\")\n",
    "    alias : str = Field(description = \"Nom de la variable\")\n",
    "    role : str = Field(description = \"Role de la variable en une phrase complète.\")\n",
    "\n",
    "PERIODES = '''\n",
    "🕓 **Période :**\n",
    "- Si aucune période n’est mentionnée dans la question → considérer une période par défaut de 90 jours avant aujourd'hui\n",
    "'''\n",
    "\n",
    "MACHINES = '''\n",
    "🗂️ **Sélection de la machine :**\n",
    "- Par défaut → `logstash-huron-k3x8f-202*`\n",
    "- Si la question mentionne **\"sigscan\"**, **\"bac\"**, ou **\"géolocalisation\"** → `sigscan`\n",
    "'''\n",
    "\n",
    "VARIABLES = '''\n",
    "- Si la question_utilisateur contient \"cycle\" : `property.operatingTime`\n",
    "- Si la question_utilisateur contient \"coupe\" : `property.cuttingTime`\n",
    "- Si la question_utilisateur contient **\"rendement de coupe\"** → ajouter `property.sumCycleTimeNet`, `property.operatingTime`\n",
    "- Si la question contient **\"programme\"** → ajouter `property.nomProgrammeSelect`\n",
    "- Si elle contient **\"outil\"** → ajouter `property.activeToolNumber`\n",
    "- Si elle contient **\"mise sous tension\"** ou **\"allumée\"** → ajouter `property.sumCycleTimeNet`\n",
    "- Si elle contient **\"consommation d’électricité\"**, **\"coût énergétique\"**, ou **\"puissance\"** → ajouter `property.power_X`, `property.power_Y`, `property.power_Z`, `property.powerSpindle`, `property.power_A`, `property.power_C`\n",
    "- Si elle contient **\"charge de la broche\"** ou **\"couple\"** → ajouter `property.spindlLoad`\n",
    "- Si elle contient **\"température\"** ou **\"chaleur\"** → ajouter `property.tempBrocheExt`\n",
    "- Si elle contient **\"alarme\"** ou **\"défaut\"** → ajouter `property.numDerniereAlarme`\n",
    "\n",
    "'''\n",
    "\n",
    "class elements_cherches(BaseModel):\n",
    "    machine_request : Machine = Field(description=\"Machine où nous voulons obtenir les informations\" + MACHINES)\n",
    "\n",
    "    periode_requete : periode = Field(description=\"Période associée à la requête\" + PERIODES)\n",
    "\n",
    "    variables_requete : List[variable] = Field(description = \"Associer les variables recherchées.\" + VARIABLES)\n",
    "\n",
    "    description : str = Field(description = \"Description des variables recherchées et explication de pourquoi ils sont là\")\n",
    "\n",
    "class request(BaseModel):\n",
    "    \"\"\"Format d'une requête à la base de donnée\"\"\"\n",
    "\n",
    "    question_utilisateur : str = Field(description = \"Question posée par l'utilisateur\")\n",
    "    intention : str = Field(description = \"Intention de la requête\")\n",
    "    type_traitement : str = Field(description = \"Type du traitement\")\n",
    "\n",
    "    elements_cherches_request : List[elements_cherches] = Field(description=\"Liste des éléments cherchés dans la base de données. On peut ajouter un autre élément à elements_cherches_request pour faire une autre requête. La description de elements_cherches explique leur rôle et ce qu'ils font\")\n",
    "\n",
    "    resultat_attendu : List[str] = Field(\"Liste des résultats attendus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f08b7db",
   "metadata": {},
   "source": [
    "**Générateur agent**\n",
    "\n",
    "Agent de charger de choisir les données adéquates à afficher pour l'utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23d345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from OrderState import OrderState\n",
    "\n",
    "from model import model_mistral_medium\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from typing import List\n",
    "from Graph_Agents.Agent import Agent\n",
    "class Element(BaseModel):\n",
    "\n",
    "    numero_dataFrame : int = Field(description = \"Numéro du dataFrame où est contenu l'élément\")\n",
    "\n",
    "class Choix(BaseModel):\n",
    "\n",
    "    choix_dataFrames : List[Element] = Field(description=\"Choix des dataFrames à afficher\")\n",
    "class Generateur_agent(Agent):\n",
    "\n",
    "    def __init__(self, Choix: BaseModel):\n",
    "        self.model_with_structured_output = model_mistral_medium.with_structured_output(Choix, include_raw=True)\n",
    "\n",
    "    def interaction(self, state: OrderState) -> OrderState:\n",
    "        \n",
    "        AGENT_JOB = f'''Tu es un agent chargé de répondre à la question {state[\"question\"]}.\n",
    "\n",
    "        Voici ce qui a été fait avant que tu reçoives les informations :*\n",
    "        Information cherchée : {state['information_chercher']}\n",
    "        Traitements : {state['traitements']}\n",
    "\n",
    "        Pour cela tu as plusieurs données disponibles. Ces données sont représentées par des DataFrames\n",
    "\n",
    "        Voici leurs informations :\n",
    "\n",
    "        '''\n",
    "\n",
    "        n = len(state['dataFrames'])\n",
    "            \n",
    "        for i in range(n):\n",
    "            AGENT_JOB +=  f\"Emplacement : {i} et colonnes : {state['dataFrames'][i].dataFrame.columns}\" + \" : \" + state['dataFrames'][i].role + \"\\n\"\n",
    "\n",
    "        AGENT_JOB += '''\n",
    "\n",
    "        Tu dois choisir lesquelles des DataFrames il faut afficher.\n",
    "        L'humain qui regardera n'aime pas voir des informations inutiles.\n",
    "        Fait en sorte de donner le plus d'informations possible en donnant le moins de DataFrame possibles.\n",
    "        L'humain n'aime pas lire trop de choses. Va à l'essentiel !\n",
    "        '''\n",
    "        AGENT_JOB += f\"\\nLes indices valides sont : {list(range(n))}\\n\"\n",
    "        AGENT_JOB += \"Tu dois répondre uniquement avec des indices dans cette liste.\\n\"\n",
    "\n",
    "        request = self.model_with_structured_output.invoke([AGENT_JOB])\n",
    "\n",
    "        state['input_tokens'], state['output_tokens'] = self.obtenir_tokens(request['raw'])\n",
    "        \n",
    "        state['prix_input_tokens'] += state['input_tokens'] * 0.4 / 10 ** 6\n",
    "        state['prix_output_tokens'] += state['output_tokens'] * 2 / 10 ** 6\n",
    "\n",
    "        print(request['parsed'])\n",
    "\n",
    "        state['request_call'] = request['parsed']\n",
    "\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a0dba2",
   "metadata": {},
   "source": [
    "**Treatment agent**\n",
    "\n",
    "Agent chargé d'effectuer des traitements sur les données recueillies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9de012",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_GENERATION_SYSINT = f'''\n",
    "        Tu es un agent interprète spécialisé dans l’industrie.\n",
    "\n",
    "        Tu essaies de répondre aux questions avec les outils qui te sont donnés, pas à pas.\n",
    "\n",
    "        Les programmes sont choisis avant le lancement des cycles.\n",
    "        Les outils sont choisis avant le lancement des coupes\n",
    "        Les alarmes se produisent durant l'exécution d'un programme avec son cycle associé\n",
    "\n",
    "        Lorsque des variables sont choisies avant la définition d'une variable, il faut choisir l'option 'avant' comme argument de INFORMATION_EN_FONCTION_AUTRE\n",
    "\n",
    "        Tu as accès aux clés de dataFrame : \\n\n",
    "\n",
    "        timestamp signifie le temps où la donnée a été prise\n",
    "        timestamp n'existe pas forcément.\n",
    "        D'autres variables peuvent représenter le temps\n",
    "\n",
    "        '''\n",
    "\n",
    "EXEMPLES = f'''\n",
    "Exemple 1 :\n",
    "Exprimer les programmes en fonction de leur cycle associé\n",
    "\n",
    "[fonction(fonction_appelee=<fonctions_existantes.INFORMATION_EN_FONCTION_AUTRE: 'information_en_fonction_autre'>, args=['avant', DataFrame contenant les cycles, DataFrame contenant les programmes)]\n",
    "\n",
    "Exemple 2 :\n",
    "Afficher les informations sur un graphique\n",
    "\n",
    "[fonction(fonction_appelee=<fonctions_existantes.CREER_GRAPHIQUE: 'creer_graphique'>, args=[DataFrames contenant les graphiques que nous voulons afficher]]\n",
    "\n",
    "Exemple 3 :\n",
    "Filtrer les programmes en acceptant que ceux contenant l'outil 130\n",
    "\n",
    "Lorsque FILTRER_VALEUR est utilisé, le premier élément de DataFrame doit toujours être associé à <strong id = \"1\">des temps de cycle</strong> ou  <strong id = \"1\">des temps de coupe </strong> et il doit contenir les attributs start et end\n",
    "\n",
    "[fonction(fonction_appelee=<fonctions_existantes.FILTRER_VALEUR: 'filtrer_valeur'>, args=['130', Element(numero_dataFrame=numéro correspondant aux outils et <strong id = \"1\">leur temps de coupe</strong>, cle_dataFrame=clé correspondant aux outils), Element(numero_dataFrame=numéro correspondant aux programmes, cle_dataFrame=clé correspondant aux programmes)])]\n",
    "\n",
    "Exemple 4 :\n",
    "Filtrer les outils ayant dépassé deux heures de coupe cumulées\n",
    "\n",
    "N'oublie pas que les numéros de dataFrame et leur clé doit exister\n",
    "\n",
    "[fonction(fonction_appelee=<fonctions_existantes.FILTRER_COMPARAISON: 'filtrer_comparaison'>, args=[Element(numero_dataFrame=numéro correspondant au temps, cle_dataFrame=clé correspondant au temps), '7200', '+inf']\n",
    "\n",
    "Exemple 5:\n",
    "Extraire les 3 premières alarmes\n",
    "\n",
    "[fonction(fonction_appelee=<fonctions_existantes.N_PREMIERS: 'filtrer_comparaison'>, args=[Element(numero_dataFrame=numéro correspondant aux alarmes, cle_dataFrame=clé correspondant aux alarmes), '3']\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc15200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Graph_Agents.Agent import Agent\n",
    "from OrderState import OrderState\n",
    "from model import model_codestral, model_mistral_medium\n",
    "\n",
    "from Tools_nodes.treatment_node.traitement_format import Traitement_Format, fonction\n",
    "\n",
    "class TreatmentAgent(Agent):\n",
    "\n",
    "    def __init__(self, fonction, prompt_job, exemples):\n",
    "\n",
    "        self.structured_llm = model_codestral.with_structured_output(fonction, include_raw=True)\n",
    "        self.prompt_job = prompt_job\n",
    "        self.exemples = exemples\n",
    "\n",
    "    def interaction(self, state: OrderState) -> OrderState:\n",
    "        \"\"\"Agent de traitement\"\"\"\n",
    "\n",
    "        if state['traitement'] != None:\n",
    "            prompt = self.creer_prompt(state['dataFrames'], state['traitement'])\n",
    "\n",
    "            print(\"Prompt donné : \\n\\n\" + prompt)\n",
    "\n",
    "        # Appelle le modèle avec prompt fusionné\n",
    "        traitement_format_result = self.structured_llm.invoke(prompt)\n",
    "\n",
    "        state['input_tokens'], state['output_tokens'] = self.obtenir_tokens(traitement_format_result['raw'])\n",
    "        \n",
    "        state['prix_input_tokens'] += state['input_tokens'] * 0.3 / 10 ** 6\n",
    "        state['prix_output_tokens'] += state['output_tokens'] * 0.9 / 10 ** 6\n",
    "\n",
    "        #print(\"🧪 Résultat traitement_format:\", traitement_format_result)\n",
    "\n",
    "        # Tu crées un NOUVEAU dict propre ici\n",
    "        updated_state = {\n",
    "            **state,\n",
    "            \"traitement_format\": traitement_format_result['parsed']\n",
    "        }\n",
    "\n",
    "        #print(\"📤 Ce que je retourne dans treatment_agent:\", list(updated_state.keys()))\n",
    "\n",
    "        return updated_state\n",
    "    \n",
    "    def creer_prompt(self, dataFrames, traitement_actuel):\n",
    "        job_message = self.prompt_job\n",
    "        job_message += self.ajouter_cles_dataFrames(dataFrames)\n",
    "        job_message += self.exemples\n",
    "        job_message += f\"\\n{traitement_actuel}\"\n",
    "\n",
    "        return job_message\n",
    "         \n",
    "    \n",
    "    def ajouter_cles_dataFrames(self, dataFrames):\n",
    "        \n",
    "        n = len(dataFrames)\n",
    "\n",
    "        job_message = \"\"\n",
    "\n",
    "        for i in range(n):\n",
    "                job_message +=  f\"Emplacement : {i} et colonnes : {dataFrames[i].dataFrame.columns}\" + \" : \" + dataFrames[i].role + \"\\n\"\n",
    "\n",
    "        job_message += '''Tu ne peux utiliser que ces clés de dataFrame. Il n'est pas possible d'en utiliser des variantes'''\n",
    "\n",
    "        return job_message\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d0331f",
   "metadata": {},
   "source": [
    "**Trieur Question**\n",
    "\n",
    "Agent chargé de déterminer s'il faut intéragir avec une base de donnée Huron ou Sigscan pour répondre à la question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18856bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class OutputSchema(BaseModel):\n",
    "            result: bool = Field(description=\"Répond uniquement 'true' si la question est liée à Huron, sinon 'false'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b764d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXEMPLES = '''\n",
    "\n",
    "Exemple 1: Repère la valeur maximum de la charge de la broche la semaine dernière et donne-moi la date          -> true\n",
    "Exemple 2: Quelle est la température maximale de la broche atteinte cette semaine et dans quel programme ?          -> true\n",
    "Exemple 3: Quel programme a la température moyenne de broche la plus élevée en mars ?          -> true\n",
    "Exemple 4: Quels sont les 3 programmes les plus souvent associés à des pics de température ?          -> true\n",
    "Exemple 5: Dans le programme XXXXX, quelle est la ligne ayant provoqué la force de coupe maximale           -> true\n",
    "Exemple 6: La semaine dernière donne-moi la liste des fois où la broche a dépassé 90°          -> true\n",
    "Exemple 7: Quels outils sont utilisé dans les cycles où la température broche a dépassé 70°C ?          -> true\n",
    "Exemple 8: Le cycle en cours a-t-il vu une température de broche dépasser les 80 ° ?          -> true\n",
    "Exemple 9: Quels programmes ont atteint une vitesse de broche supérieure à 3000tr/min deux fois ou plus ?          -> true\n",
    "Exemple 10: Liste-moi les jours où la vitesse de la broche a dépassé 4000 tour/min depuis un mois.          -> true\n",
    "Exemple 11: Est-ce que la charge de broche a dépassé les seuils de 7 les 20 derniers jours          -> true\n",
    "\n",
    "Exemple 12: Donne-moi le temps d'usinage de chaque outil depuis un mois          -> true\n",
    "Exemple 13: En février, quels outils ont dépassé 2 heures de coupe cumulées ?          -> true\n",
    "Exemple 14: Dans le programme XXXX donne-moi le temps de coupe moyen de chaque outil          -> true\n",
    "Exemple 15: Dans le dernier cycle du programme XXXX, quel outil a été le plus utilisé ?          -> true\n",
    "Exemple 16: Quels outils sont utilisés dans les programmes actifs cette semaine ?          -> true\n",
    "\n",
    "Exemple 25: Compare le temps total d’usinage avec le temps d’allumage machine depuis lundi.          -> true\n",
    "Exemple 26: Quel est le rendement de coupe en mars          -> true\n",
    "Exemple 27: Quel est le rendement de coupe moyen pour les séries réalisées entre le 15 mars et le 28 mars ?          -> true\n",
    "Exemple 28: Quels programmes présentent un rendement de coupe inférieur à 0.6 ?          -> true\n",
    "Exemple 29: Quel est le temps total d’allumage de la Huron entre le 10 et le 20 mars ?          -> true\n",
    "\n",
    "Exemple 30: Liste-moi les alarmes apparu dans les 3 derniers jours          -> true\n",
    "Exemple 31: Quelle sont les 3 alarmes les plus récurrentes le mois dernier          -> true\n",
    "Exemple 32: Présente moi le paréto des alarmes du 6 au 28 mars          -> true\n",
    "Exemple 33: Quelle est l’alarme qui revient le plus sur le programme XXXX          -> true\n",
    "Exemple 34: La semaine dernière quel est le programme qui a engendré le plus d’alarme          -> true\n",
    "\n",
    "Exemple 35: Quel est le programme en cours de la Huron          -> true\n",
    "Exemple 36: Quel est l’état de cycle actuel de la Huron          -> true\n",
    "\n",
    "Exemple 37: Liste-moi les cycles du programme XXXX du mois dernier          -> true\n",
    "Exemple 38: Quel est le temps de cycle moyen pour le programme XXXXX          -> true\n",
    "Exemple 39: Quels cycles ont été exécutés après 16h          -> true\n",
    "Exemple 40: Liste les cycles et les programmes associés          -> true\n",
    "Exemple 41: Quels sont les outils utilisés dans le programme _N_OP20_AIR_SPF          -> true\n",
    "Exemple 42: Quel jour la machine est restée allumée après 18h ?          -> true\n",
    "\n",
    "Exemple 43: Quelles sont les positions du 02/02/2024 au 10/05/2024 du Chariot ?          -> false\n",
    "Exemple 44: Illustre les pièces présentes dans la zone Tournage du 01/03/2025 au 01/06/2025          -> false\n",
    "Exemple 45: Liste les pièces et leur zone associée          -> false\n",
    "Exemple 46: Liste les fois où le Chariot est passé dans la zone Jet d'eau du 12/08/2025 au 19/10/2025          -> false\n",
    "\n",
    "'''\n",
    "AGENT_JOB = f'''\n",
    "Tu es un agent de tri **binaire** spécialisé dans la classification des questions selon qu’elles concernent **la machine Huron** ou **le système de supervision Sigscan**.\n",
    "\n",
    "Tu dois analyser chaque question et répondre exclusivement par :\n",
    "- `true` → si la question concerne Huron\n",
    "- `false` → si elle concerne Sigscan\n",
    "\n",
    "### 🎯 Règles de décision :\n",
    "\n",
    "1. Si la question parle :\n",
    "   - de **programmes Huron** (ex : `_N_OP20_AIR_SPF`, `XXXX`, `XXXXX`)\n",
    "   - d’**outils**, **cycles**, **temps de coupe**, **rendement**, **états machine**, **température broche**, **vitesse broche**\n",
    "   - ou de **la machine Huron directement** (ex : \"programme en cours de la Huron\")\n",
    "   \n",
    "   → alors réponds `true`\n",
    "\n",
    "2. Si la question mentionne des objets du système Sigscan :\n",
    "   - `Chariot`, `OF-1133`, `Stock-11`, `OF-1111`, `OF-1122`\n",
    "   - ou des zones comme `Assemblage`, `Jet d'eau`, `Tournage`, `Usinage`\n",
    "   \n",
    "   → alors réponds `false`\n",
    "\n",
    "3. Si la question semble ambigüe, **appuie-toi sur les exemples** ci-dessous. Tu dois faire au mieux pour classer.\n",
    "\n",
    "---\n",
    "\n",
    "Voici des exemples de questions et la réponse attendue :\n",
    "\n",
    "{EXEMPLES}\n",
    "\n",
    "Ta réponse doit être uniquement `true` ou `false`, encapsulée dans un objet `OutputSchema`.\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25c3bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, List\n",
    "from OrderState import OrderState\n",
    "from model import model_codestral, model_mistral_medium\n",
    "from Graph_Agents.TrieurQuestion.Trieur_prompt import AGENT_JOB\n",
    "\n",
    "from Graph_Agents.Agent import Agent\n",
    "\n",
    "from datetime import datetime\n",
    "class Trieur_question_agent(Agent):\n",
    "    \"Agent responsible for processing if the question is related to Sigscan or HURON\"\n",
    "\n",
    "    def __init__(self, OutputSchema):\n",
    "        self.structured_llm = model_mistral_medium.with_structured_output(OutputSchema, include_raw=True)\n",
    "\n",
    "    def interaction(self, state: OrderState) -> OrderState:\n",
    "        new_output = self.structured_llm.invoke([AGENT_JOB, state['question']])\n",
    "        print(f\"Réponse brute : {new_output}\")\n",
    "        state['input_tokens'], state['output_tokens'] = self.obtenir_tokens(new_output['raw'])\n",
    "        state['prix_input_tokens'] += state['input_tokens'] * 0.4 / 10 ** 6\n",
    "        state['prix_output_tokens'] += state['output_tokens'] * 2 / 10 ** 6\n",
    "\n",
    "        parsed = new_output.get('parsed')\n",
    "        if parsed is not None and hasattr(parsed, 'result'):\n",
    "            val = parsed.result\n",
    "            if val:\n",
    "                state['Huron_related'] = True\n",
    "            elif not val:\n",
    "                state['Huron_related'] = False\n",
    "            else:\n",
    "                raise ValueError(f\"Valeur inattendue pour result: {val}\")\n",
    "            print(f\"✅ Question en relation avec Huron : {state['Huron_related']}\")\n",
    "        else:\n",
    "            raise ValueError(\"❌ Parsing échoué : pas de champ 'result' dans la sortie.\")\n",
    "\n",
    "        print(f\"Question en relation avec Huron : {state['Huron_related']}\\n\")\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c6f55e",
   "metadata": {},
   "source": [
    "**Human Node**\n",
    "\n",
    "Noeud chargé de l'intéraction avec un humain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eeef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from OrderState import OrderState\n",
    "from typing import Literal\n",
    "from langgraph.graph import END\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "WELCOME_MSG = \"Bonjour ! Je suis votre assistant, comment puis-je vous aider?\"\n",
    "\n",
    "def obtenir_date_ajd():\n",
    "    return f\"\\nNous sommes le {datetime.now()}\"\n",
    "\n",
    "def human_node(state: OrderState) -> OrderState:\n",
    "    \n",
    "    if not state[\"messages\"]:\n",
    "        # Premier tour : injecter le message de bienvenue\n",
    "        state[\"messages\"].append(AIMessage(content=WELCOME_MSG))\n",
    "        state[\"finished\"] = True  # Stopper pour éviter de re-boucler\n",
    "        return state\n",
    "    \n",
    "    #Calcul des tokens\n",
    "\n",
    "    print(f\"Input token : {state['input_tokens']}\\nOutput_token : {state['output_tokens']}\")\n",
    "    print(f\"Prix Input token : {state['prix_input_tokens']}\\nPrix Output_token : {state['prix_output_tokens']}\")\n",
    "    state['latest_input_tokens'] = state['input_tokens']\n",
    "    state['latest_output_tokens'] = state['output_tokens']\n",
    "    state['input_tokens'] = 0\n",
    "    state['output_tokens'] = 0\n",
    "\n",
    "    state['prix_input_tokens'] = 0\n",
    "    state['prix_output_tokens'] = 0\n",
    "\n",
    "    last_msg = state[\"messages\"][-1] \n",
    "\n",
    "    if isinstance(last_msg, AIMessage):\n",
    "        state[\"finished\"] = True\n",
    "    elif isinstance(last_msg, HumanMessage):\n",
    "        print(\"[Utilisateur]:\", last_msg.content + obtenir_date_ajd())\n",
    "        state[\"question\"] = last_msg.content + obtenir_date_ajd()\n",
    "\n",
    "    print(f\"\"\"state : {state[\"finished\"]}\"\"\")\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    \"\"\"Display the last model message to the user, and receive the user's input.\"\"\"\n",
    "    last_msg = state[\"messages\"][-1]\n",
    "    print(\"Model:\", last_msg.content)\n",
    "\n",
    "    user_input = input(\"User: \")\n",
    "\n",
    "    # If it looks like the user is trying to quit, flag the conversation\n",
    "    # as over.\n",
    "    if user_input in {\"q\", \"quit\", \"exit\", \"goodbye\"}:\n",
    "        state[\"finished\"] = True\n",
    "\n",
    "    return state | {\"messages\": [HumanMessage(user_input)]}\n",
    "    '''\n",
    "\n",
    "def maybe_exit_human_node(state: OrderState) -> Literal[\"Trieur de questions\", \"__end__\"]:\n",
    "    if state[\"finished\"]:\n",
    "        return END\n",
    "    return \"Trieur de questions\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d543f09",
   "metadata": {},
   "source": [
    "CollapsibleBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28db9aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PySide6.QtWidgets import QGroupBox, QVBoxLayout, QToolButton, QWidget, QSizePolicy\n",
    "from PySide6.QtCore import Qt, QPropertyAnimation, QEasingCurve\n",
    "\n",
    "\n",
    "class CollapsibleBox(QGroupBox):\n",
    "    def __init__(self, title=\"\", parent=None):\n",
    "        super().__init__(parent)\n",
    "        self.toggle_button = QToolButton()\n",
    "        self.toggle_button.setText(title)\n",
    "        self.toggle_button.setCheckable(True)\n",
    "        self.toggle_button.setChecked(False)\n",
    "        self.toggle_button.setArrowType(Qt.RightArrow)  # 🔼 flèche initiale\n",
    "        self.toggle_button.setToolButtonStyle(Qt.ToolButtonTextBesideIcon)\n",
    "        self.toggle_button.setSizePolicy(QSizePolicy.Maximum, QSizePolicy.Fixed)  # ⬅️ largeur minimale\n",
    "        self.toggle_button.clicked.connect(self.toggle_content)\n",
    "\n",
    "        self.content_area = QWidget()\n",
    "        self.content_area.setVisible(False)\n",
    "        self.content_area.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Fixed)\n",
    "        self.content_area.setMaximumHeight(0)  # 🔥 important pour anim correcte\n",
    "        self.toggle_button.setStyleSheet(\"\"\"\n",
    "            QToolButton {\n",
    "                background-color: #E3F2FD;\n",
    "                border: 1px solid #90CAF9;\n",
    "                border-radius: 6px;\n",
    "                padding: 6px 12px;\n",
    "                font-weight: bold;\n",
    "                color: #1565C0;\n",
    "                text-align: left;\n",
    "            }\n",
    "            QToolButton:hover {\n",
    "                background-color: #BBDEFB;\n",
    "            }\n",
    "            QToolButton:pressed {\n",
    "                background-color: #90CAF9;\n",
    "            }\n",
    "        \"\"\")\n",
    "        \n",
    "\n",
    "        layout = QVBoxLayout()\n",
    "        layout.addWidget(self.toggle_button)\n",
    "        layout.addWidget(self.content_area)\n",
    "        self.setLayout(layout)\n",
    "\n",
    "    def toggle_content(self):\n",
    "        expanded = self.content_area.isVisible()\n",
    "        direction = not expanded  # True si on va ouvrir\n",
    "\n",
    "        self.toggle_button.setArrowType(Qt.DownArrow if direction else Qt.RightArrow)\n",
    "\n",
    "        if direction:\n",
    "            self.content_area.setVisible(True)\n",
    "            self.content_area.adjustSize()\n",
    "            target_height = self.content_area.sizeHint().height()\n",
    "        else:\n",
    "            target_height = 0\n",
    "\n",
    "        self.animation = QPropertyAnimation(self.content_area, b\"maximumHeight\")\n",
    "        self.animation.setDuration(300)\n",
    "        self.animation.setStartValue(self.content_area.height())\n",
    "        self.animation.setEndValue(target_height)\n",
    "        self.animation.setEasingCurve(QEasingCurve.OutCubic)\n",
    "        self.animation.start()\n",
    "\n",
    "        if not direction:\n",
    "            # Cache le widget à la fin de l’animation\n",
    "            self.animation.finished.connect(lambda: self.content_area.setVisible(False))\n",
    "\n",
    "    def setContent(self, content_widget):\n",
    "        content_layout = QVBoxLayout()\n",
    "        content_layout.addWidget(content_widget)\n",
    "        self.content_area.setLayout(content_layout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304c5098",
   "metadata": {},
   "source": [
    "controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a33a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ui.view import ChatWindow\n",
    "from ui.worker import Worker\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from PySide6.QtCore import QThread, QMetaObject, Qt, Q_ARG\n",
    "from PySide6.QtWidgets import QFileDialog, QMessageBox\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "#from langchain_core.messages import AIMessage\n",
    "#from logic.core import process_user_input\n",
    "\n",
    "from index import formalisateur_requete\n",
    "\n",
    "class ChatController:\n",
    "    style = \"padding-left: 20px; margin: 0; white-space: pre-wrap; font-family: Consolas, monospace; line-height: 1.4em;\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.view = None\n",
    "        self.history = []\n",
    "        self.state = None  # 🆕 stocke le dernier état\n",
    "\n",
    "    def set_view(self, view: ChatWindow):\n",
    "        self.view = view\n",
    "        self.view.set_controller(self)  # 🆕 (permet à la vue d'accéder au contrôleur)\n",
    "    def save_history_to_file(self):\n",
    "        # 📁 Création du dossier \"exports\" s'il n'existe pas\n",
    "        export_dir = os.path.join(os.getcwd(), \"exports\")\n",
    "        os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "        # 🕒 Nom par défaut avec timestamp\n",
    "        default_filename = f\"historique_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "        default_path = os.path.join(export_dir, default_filename)\n",
    "\n",
    "        # 💬 Fenêtre de dialogue\n",
    "        path, _ = QFileDialog.getSaveFileName(\n",
    "            self.view,\n",
    "            \"Enregistrer l'historique\",\n",
    "            default_path,\n",
    "            \"Fichiers JSON (*.json)\"\n",
    "        )\n",
    "\n",
    "        if not path:\n",
    "            return  # utilisateur a annulé\n",
    "\n",
    "        if not path.endswith(\".json\"):\n",
    "            path += \".json\"\n",
    "\n",
    "        try:\n",
    "            # 🧼 Conversion des objets non-sérialisables\n",
    "            serializable_history = []\n",
    "            for msg in self.history:\n",
    "                if isinstance(msg, HumanMessage):\n",
    "                    serializable_history.append({\"role\": \"user\", \"content\": msg.content})\n",
    "                elif isinstance(msg, AIMessage):\n",
    "                    serializable_history.append({\"role\": \"ai\", \"content\": msg.content})\n",
    "\n",
    "            with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(serializable_history, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "            print(f\"✅ Historique enregistré avec succès dans : {path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            self.view.display_error(f\"Erreur lors de la sauvegarde : {str(e)}\")\n",
    "    def display_welcome_message(self):\n",
    "        welcome = (\n",
    "            \"👋 Bonjour ! Je suis votre assistant pour la supervision industrielle.\\n\"\n",
    "            \"Posez-moi une question sur les machines, les outils, les alarmes ou la production !\"\n",
    "        )\n",
    "        self.view.display_response(welcome)\n",
    "        self.history.append(AIMessage(content=welcome))  # 🔄 Historique\n",
    "\n",
    "    def load_history_from_file(self, filepath):\n",
    "        confirm = QMessageBox.StandardButton.Yes\n",
    "        if self.history:\n",
    "            confirm = QMessageBox.question(\n",
    "                self.view,\n",
    "                \"Confirmation\",\n",
    "                \"⚠️ Cette action va effacer la conversation actuelle. Voulez-vous continuer ?\",\n",
    "                QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No\n",
    "            )\n",
    "        if confirm == QMessageBox.StandardButton.No:\n",
    "            return\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            raw_history = json.load(f)\n",
    "\n",
    "        self.history = []\n",
    "        while self.view.chat_layout.count():\n",
    "            child = self.view.chat_layout.takeAt(0)\n",
    "            if child.widget():\n",
    "                child.widget().deleteLater()\n",
    "\n",
    "        last_user_msg = None\n",
    "        last_ai_msg = None\n",
    "\n",
    "        for msg in raw_history:\n",
    "            if msg[\"role\"] == \"user\":\n",
    "                if last_user_msg and last_ai_msg:\n",
    "                    # Afficher la dernière réponse IA avant de passer au prochain user\n",
    "                    self.view.display_response(last_ai_msg)\n",
    "\n",
    "                self.history.append(HumanMessage(content=msg[\"content\"]))\n",
    "                self.view.append_message(\"Vous\", msg[\"content\"])\n",
    "                last_user_msg = msg[\"content\"]\n",
    "                last_ai_msg = None\n",
    "\n",
    "            elif msg[\"role\"] == \"ai\":\n",
    "                self.history.append(AIMessage(content=msg[\"content\"]))\n",
    "                last_ai_msg = msg[\"content\"]\n",
    "\n",
    "        # Affiche la dernière réponse IA si présente\n",
    "        if last_ai_msg:\n",
    "            self.view.display_response(last_ai_msg)\n",
    "    def open_history_file_dialog(self):\n",
    "        path, _ = QFileDialog.getOpenFileName(\n",
    "            self.view,\n",
    "            \"Ouvrir un historique\",\n",
    "            \"\",\n",
    "            \"Fichiers JSON (*.json)\"\n",
    "        )\n",
    "        if path:\n",
    "            self.load_history_from_file(path)\n",
    "    def _format_summary(self, state):\n",
    "        req = state.get(\"request_call\", None)\n",
    "\n",
    "        if state.get(\"Huron_related\"):\n",
    "            req_init = state.get(\"request_call_initial\", None)\n",
    "        else:\n",
    "            req_init = req\n",
    "        fonctions = state.get(\"traitement_format\", None)\n",
    "        traitements = state.get(\"traitements\", None)\n",
    "        input_tokens = state.get(\"latest_input_tokens\", None)\n",
    "        output_tokens = state.get(\"latest_output_tokens\", None)\n",
    "\n",
    "        if not req:\n",
    "            return \"🤷 Je n’ai pas pu extraire la requête utilisateur.\"\n",
    "\n",
    "        if type(req_init) != formalisateur_requete.dict_Structure:\n",
    "            lines = []\n",
    "            lines.append(\"📋 Résumé de la requête\\n\")\n",
    "            lines.append(\"Nombre de tokens utilisés:\\n\")\n",
    "            lines.append(f\"    ➡️ Tokens d'entrée : {input_tokens}\")\n",
    "            lines.append(f\"    ➡️ Tokens de sortie : {output_tokens}\\n\")\n",
    "            lines.append(f\"🧠 Question : {req_init.question_utilisateur}\")\n",
    "            lines.append(f\"🎯 Intention : {req_init.intention}\")\n",
    "            lines.append(f\"📂 Type de traitement : {req_init.type_traitement}\\n\")\n",
    "            if hasattr(req, \"choix_dataFrames\"):\n",
    "                lines.append(\"✅ DataFrames choisis pour affichage :\")\n",
    "                for i, elem in enumerate(req.choix_dataFrames):\n",
    "                    lines.append(f\"    📄 DataFrame {i + 1} : Index {elem.numero_dataFrame}\")\n",
    "\n",
    "            if req_init.elements_cherches_request:\n",
    "                el = req_init.elements_cherches_request[0]\n",
    "\n",
    "                if el.periode_requete:\n",
    "                    date_from = el.periode_requete.date_from.split(\"T\")[0]\n",
    "                    date_to = el.periode_requete.date_to.split(\"T\")[0]\n",
    "                    lines.append(f\"\\n🗓️ Période : {date_from} → {date_to}\")\n",
    "                if el.machine_request:\n",
    "                    lines.append(f\"🏭 Machine : {el.machine_request.name}\")\n",
    "                if el.variables_requete:\n",
    "                    lines.append(\"🔧 Variables de la requête :\")\n",
    "                    for v in el.variables_requete:\n",
    "                        lines.append(f\"    ➡️ {v.role} : {v.alias}\")\n",
    "\n",
    "            if req_init.resultat_attendu:\n",
    "                try:\n",
    "                    lines.append(f\"\\n📌 Résultat attendu : {', '.join(req_init.resultat_attendu)}\")\n",
    "                except TypeError:\n",
    "                    lines.append(f\"📌 Résultat attendu : {req_init.resultat_attendu}\")\n",
    "\n",
    "            lines.append(\"\\n🔧 Traitements effectués :\")\n",
    "            if traitements:\n",
    "                for i, t in enumerate(traitements):\n",
    "                    lines.append(f\"    ➡️ Traitement {i + 1} : {t}\")\n",
    "            else:\n",
    "                lines.append(\"    ➡️ Aucun traitement déclaré\")\n",
    "\n",
    "            lines.append(\"\\n🛠️ Fonctions appliquées :\")\n",
    "            if fonctions and hasattr(fonctions, \"fonction_appelee\"):\n",
    "                args_str = ', '.join(str(arg) for arg in fonctions.args)\n",
    "                lines.append(f\"    ⚙️ Fonction : {fonctions.fonction_appelee.value} avec args {args_str}\")\n",
    "            else:\n",
    "                lines.append(\"    ⚙️ Aucune fonction détectée ou applicable\")\n",
    "        else:\n",
    "            lines = []\n",
    "            if req_init.object:\n",
    "                lines.append(f\"Objet(s) recherché(s): {req_init.object}\")\n",
    "            else:\n",
    "                lines.append(\"Objet(s) recherché(s): Tous les objets\")\n",
    "            if req_init.area:\n",
    "                lines.append(f\"Zone(s) recherchée(s): {req_init.area}\")\n",
    "            else:\n",
    "                lines.append(\"Zone(s) recherchée(s): Toutes les zones\")\n",
    "            if req_init.startDate and req_init.endDate:\n",
    "                lines.append(f\"Période: {req_init.startDate} ->  {req_init.endDate}\")\n",
    "            else:\n",
    "                lines.append(\"Période: 90 jours avant aujourd'hui\")\n",
    "\n",
    "        # 💡 Converti le tout dans un bloc HTML <pre> avec style propre\n",
    "        content = \"\\n\".join(lines)\n",
    "        return f\"<pre style='font-family: Consolas, monospace; font-size: 13px; line-height: 1.4em; white-space: pre-wrap; margin: 0;'>{content}</pre>\"\n",
    "\n",
    "\n",
    "    def on_send_clicked(self):\n",
    "        user_text = self.view.input_field.text().strip()\n",
    "        if not user_text:\n",
    "            return\n",
    "        self.view.input_field.clear()\n",
    "        self.view.append_message(\"Vous\", user_text)\n",
    "        self.view.show_loading()\n",
    "\n",
    "        self.thread = QThread()\n",
    "        self.worker = Worker(self.history, user_text)\n",
    "        self.worker.moveToThread(self.thread)\n",
    "\n",
    "        self.thread.started.connect(self.worker.run)\n",
    "        self.worker.finished.connect(self._on_worker_finished)\n",
    "        self.worker.error.connect(self._on_worker_error)\n",
    "        self.worker.finished.connect(self.thread.quit)\n",
    "        self.worker.finished.connect(self.worker.deleteLater)\n",
    "        self.thread.finished.connect(self.thread.deleteLater)\n",
    "\n",
    "        self.thread.start()\n",
    "        \"\"\" try:\n",
    "            result = process_user_input(self.history, user_text)\n",
    "            self.history = result[\"messages\"]\n",
    "            try:\n",
    "                summary = self._format_summary(result[\"state\"])\n",
    "                \n",
    "                self.view.append_collapsible_summary(summary)\n",
    "            except Exception as e:\n",
    "                print(\"Erreur dans le résumé:\", e)\n",
    "            last_message = self.history[-1]\n",
    "            if last_message.type == \"ai\":\n",
    "                self.view.display_response(last_message.content)\n",
    "\n",
    "        except Exception as e:\n",
    "            self.view.append_message(\"Erreur\", str(e))\n",
    "        finally:\n",
    "            self.view.hide_loading() \"\"\"\n",
    "    def _on_worker_finished(self, history, state):\n",
    "        self.history = history\n",
    "        self.state = state\n",
    "\n",
    "        # 🧠 Appelle \"update_after_response\" sur la vue dans le bon thread\n",
    "        QMetaObject.invokeMethod(self.view, \"update_after_response\")\n",
    "\n",
    "    def _on_worker_error(self, error_msg):\n",
    "        QMetaObject.invokeMethod(\n",
    "            self.view,\n",
    "            b\"display_error\",\n",
    "            Qt.QueuedConnection,\n",
    "            Q_ARG(str, str(error_msg))\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b53c9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "QWidget {\n",
    "    background-color: #2E2E2E;\n",
    "    color: #E0E0E0;\n",
    "    font-family: \"Segoe UI\", sans-serif;\n",
    "}\n",
    "QLineEdit, QTextEdit {\n",
    "    background-color: white;\n",
    "    color: black;\n",
    "    border: 1px solid #ccc;\n",
    "}\n",
    "QPushButton {\n",
    "    background-color: #444;\n",
    "    color: white;\n",
    "    border: 1px solid #666;\n",
    "    padding: 5px;\n",
    "}\n",
    "QScrollArea {\n",
    "    background-color: #2E2E2E;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d6ac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "QWidget {\n",
    "    background-color: #F5F5F5;\n",
    "    color: #333;\n",
    "    font-family: \"Segoe UI\", sans-serif;\n",
    "}\n",
    "QLineEdit, QTextEdit {\n",
    "    background-color: white;\n",
    "    color: black;\n",
    "    border: 1px solid #ccc;\n",
    "}\n",
    "QPushButton {\n",
    "    background-color: #e0e0e0;\n",
    "    color: black;\n",
    "    border: 1px solid #aaa;\n",
    "    padding: 5px;\n",
    "}\n",
    "QScrollArea {\n",
    "    background-color: #f5f5f5;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9fe897",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PREFERENCES = {\n",
    "    \"theme\": \"dark\"  # ou \"light\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fb2c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PySide6.QtWidgets import QWidget, QVBoxLayout, QFrame, QTextBrowser, QLineEdit, QPushButton, QHBoxLayout, QApplication, QFileDialog, QLabel, QSpacerItem, QSizePolicy, QScrollArea, QGraphicsOpacityEffect, QGraphicsDropShadowEffect\n",
    "import markdown2\n",
    "from ui.CollapsibleBox import CollapsibleBox \n",
    "from PySide6.QtCore import Qt, QTimer, QSize, QPropertyAnimation, QParallelAnimationGroup, QEasingCurve\n",
    "from PySide6.QtGui import QMovie, QPixmap\n",
    "import os\n",
    "from PySide6.QtCore import Slot\n",
    "from langchain_core.messages import AIMessage\n",
    "from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FigureCanvas\n",
    "from ui.settings import USER_PREFERENCES\n",
    "# Vue de la fenêtre de chat\n",
    "class ChatWindow(QWidget):\n",
    "    # Constructeur de la fenêtre de chat\n",
    "    def __init__(self, controller):\n",
    "        super().__init__() # Appel du constructeur de QWidget\n",
    "        self._active_animations = []\n",
    "        self.setWindowTitle(\"Assistant Industriel 🤖\") # Titre de la fenêtre\n",
    "        self.setMinimumSize(600, 500) # Taille minimale de la fenêtre\n",
    "        self.controller = controller # Stockage du contrôleur\n",
    "\n",
    "        self.layout = QVBoxLayout() # Création du layout vertical\n",
    "        self.setLayout(self.layout) # Application du layout à la fenêtre\n",
    "        # Layout des boutons \"Exporter\" et \"Charger\"\n",
    "        action_layout = QHBoxLayout()\n",
    "        self.save_button = QPushButton(\"📥 Exporter le chat\")\n",
    "        self.load_button = QPushButton(\"📂 Charger l'historique\")\n",
    "        self.theme_toggle_button = QPushButton()\n",
    "        self.theme_toggle_button.setCursor(Qt.PointingHandCursor)\n",
    "        self.theme_toggle_button.setFixedSize(36, 36)\n",
    "        self.theme_toggle_button.setStyleSheet(\"border: none; background: transparent; font-size: 18px;\")\n",
    "        self.update_theme_icon()  # 🌞 ou 🌙\n",
    "\n",
    "        self.save_button.clicked.connect(lambda: self.controller.save_history_to_file())\n",
    "        self.load_button.clicked.connect(lambda: self.controller.open_history_file_dialog())\n",
    "        self.theme_toggle_button.clicked.connect(self.toggle_theme)\n",
    "\n",
    "        action_layout.addWidget(self.save_button)\n",
    "        action_layout.addWidget(self.load_button)\n",
    "        action_layout.addWidget(self.theme_toggle_button)\n",
    "\n",
    "        self.layout.addLayout(action_layout)  # ➕ tout en haut\n",
    "        self.chat_scroll = QScrollArea()\n",
    "        self.chat_scroll.setWidgetResizable(True)\n",
    "        self.chat_scroll.setStyleSheet(\"QScrollArea { background: #fefefe; border: 1px solid #ccc; border-radius: 5px; }\")\n",
    "\n",
    "        self.chat_container = QWidget()\n",
    "        self.chat_layout = QVBoxLayout()\n",
    "        self.chat_layout.setAlignment(Qt.AlignTop)  # 🔥 aligne en haut\n",
    "        self.chat_container.setLayout(self.chat_layout)\n",
    "\n",
    "        self.chat_scroll.setWidget(self.chat_container)\n",
    "        self.layout.addWidget(self.chat_scroll)\n",
    "\n",
    "        #self.chat_display = QTextEdit() # Zone d'affichage du chat\n",
    "        #self.chat_display.setReadOnly(True) # Rendre la zone d'affichage en lecture seule\n",
    "\n",
    "        #self.layout.addWidget(self.chat_display) # Ajout de la zone d'affichage au layout\n",
    "\n",
    "        input_layout = QHBoxLayout() # Création du layout horizontal pour les entrées\n",
    "        self.input_field = QLineEdit() # Champ de saisie pour l'utilisateur\n",
    "        self.input_field.setPlaceholderText(\"Posez votre question ici...\") # Texte d'instruction\n",
    "         # Bouton d'envoi\n",
    "        self.send_button = QPushButton(\"Envoyer\")\n",
    "        self.send_button.setToolTip(\"Envoyer votre question\")\n",
    "        # Bouton pour quitter l'application\n",
    "        self.quit_button = QPushButton(\"Quitter\")\n",
    "        self.quit_button.setToolTip(\"Quitter l'application\")\n",
    "        # --- Chargement GIF + Texte ---\n",
    "        gif_path = os.path.join(os.path.dirname(__file__), \"assets\", \"thinking-ezgif.com-crop.gif\")\n",
    "        self.loading_movie = QMovie(gif_path)\n",
    "        self.loading_movie.setScaledSize(QSize(24, 24))\n",
    "\n",
    "        self.loading_gif_label = QLabel()\n",
    "        self.loading_gif_label.setMovie(self.loading_movie)\n",
    "        self.loading_gif_label.setAlignment(Qt.AlignLeft | Qt.AlignVCenter)\n",
    "        self.loading_gif_label.setStyleSheet(\"margin: 0px; padding: 0px;\")\n",
    "\n",
    "        self.loading_text_label = QLabel(\"Réflexion en cours…\")\n",
    "        self.loading_text_label.setAlignment(Qt.AlignLeft | Qt.AlignVCenter)\n",
    "        self.loading_text_label.setStyleSheet(\"margin: 0px; padding: 0px;\")\n",
    "\n",
    "        # 📦 Layout horizontal avec un spacer à droite pour pousser les widgets à gauche\n",
    "        self.loading_layout = QHBoxLayout()\n",
    "        self.loading_layout.setContentsMargins(0, 0, 0, 0)\n",
    "        self.loading_layout.setSpacing(0)\n",
    "        self.loading_layout.addWidget(self.loading_gif_label)\n",
    "        self.loading_layout.addWidget(self.loading_text_label)\n",
    "        \n",
    "        \n",
    "\n",
    "        # 🧱 Ajout du spacer à droite\n",
    "        spacer = QSpacerItem(1, 1, QSizePolicy.Expanding, QSizePolicy.Minimum)\n",
    "        self.loading_layout.addItem(spacer)\n",
    "\n",
    "        self.loading_widget = QWidget()\n",
    "        self.loading_widget.setLayout(self.loading_layout)\n",
    "        self.loading_widget.setVisible(False)  # Caché par défaut\n",
    "\n",
    "        # N'oublie pas de l’ajouter au layout principal\n",
    "        self.layout.addWidget(self.loading_widget)\n",
    "        \n",
    "        # Ajout du champ de saisie et du bouton au layout horizontal\n",
    "        input_layout.addWidget(self.input_field)\n",
    "        input_layout.addWidget(self.send_button)\n",
    "        input_layout.addWidget(self.quit_button)\n",
    "        self.layout.addLayout(input_layout)\n",
    "        \n",
    "        self.send_button.clicked.connect(self.controller.on_send_clicked) # Connexion du bouton d'envoi à la méthode du contrôleur\n",
    "        self.input_field.returnPressed.connect(self.controller.on_send_clicked) # Connexion de la touche \"Entrée\" à la méthode du contrôleur\n",
    "        self.quit_button.clicked.connect(QApplication.instance().quit) # Connexion du bouton de quitter à l'application\n",
    "        self.summary_box = None  # 🔥 pour mémoriser la box actuelle\n",
    "        self.fade_animation = None\n",
    "\n",
    "        #self.append_collapsible_summary(\"<b>Résumé de test</b>\")\n",
    "        self.dots_timer = QTimer()\n",
    "        self.dots_timer.timeout.connect(self._animate_loading_text)\n",
    "        self.dots_state = 0\n",
    "        style = \"\"\"\n",
    "        /* Bouton générique */\n",
    "        QPushButton {\n",
    "            border: none;\n",
    "            padding: 8px 14px;\n",
    "            border-radius: 6px;\n",
    "            font-size: 14px;\n",
    "            font-weight: bold;\n",
    "            min-width: 90px;\n",
    "        }\n",
    "\n",
    "        /* Effet hover (zoom) */\n",
    "        QPushButton:hover {\n",
    "            padding: 9px 15px;\n",
    "        }\n",
    "\n",
    "        /* Bouton Envoyer (Bleu) */\n",
    "        QPushButton#send_button {\n",
    "            background-color: #2196F3;\n",
    "            color: white;\n",
    "        }\n",
    "        QPushButton#send_button:hover {\n",
    "            background-color: #1976D2;\n",
    "        }\n",
    "        QPushButton#send_button:pressed {\n",
    "            background-color: #0D47A1;\n",
    "        }\n",
    "\n",
    "        /* Bouton Quitter (Rouge) */\n",
    "        QPushButton#quit_button {\n",
    "            background-color: #f44336;\n",
    "            color: white;\n",
    "        }\n",
    "        QPushButton#quit_button:hover {\n",
    "            background-color: #d32f2f;\n",
    "        }\n",
    "        QPushButton#quit_button:pressed {\n",
    "            background-color: #b71c1c;\n",
    "        }\n",
    "\n",
    "        /* Boutons du haut (Gris/bleu clair) */\n",
    "        QPushButton#load_button,\n",
    "        QPushButton#save_button,\n",
    "        summary_box.toggle_button {\n",
    "            background-color: #e0e0e0;\n",
    "            color: #333;\n",
    "        }\n",
    "        QPushButton#load_button:hover,\n",
    "        QPushButton#save_button:hover {\n",
    "            background-color: #bdbdbd;\n",
    "        }\n",
    "        QPushButton#load_button:pressed,\n",
    "        QPushButton#save_button:pressed {\n",
    "            background-color: #9e9e9e;\n",
    "        }\n",
    "        \"\"\"\n",
    "        self.input_field.setStyleSheet(\"\"\"\n",
    "            QLineEdit {\n",
    "                padding: 8px 12px;\n",
    "                border: 2px solid #ccc;\n",
    "                border-radius: 6px;\n",
    "                font-size: 14px;\n",
    "                background-color: #ffffff;\n",
    "                color: #333;\n",
    "            }\n",
    "\n",
    "            QLineEdit:focus {\n",
    "                border: 2px solid #2196F3;\n",
    "                background-color: #f0f8ff;\n",
    "            }\n",
    "        \"\"\")\n",
    "        for btn in [self.send_button, self.quit_button, self.save_button, self.load_button]:\n",
    "            btn.setCursor(Qt.PointingHandCursor)\n",
    "\n",
    "        self.setStyleSheet(style)\n",
    "\n",
    "        self.send_button.setObjectName(\"send_button\")\n",
    "        self.quit_button.setObjectName(\"quit_button\")\n",
    "        self.load_button.setObjectName(\"load_button\")\n",
    "        self.save_button.setObjectName(\"save_button\")\n",
    "        self.apply_theme()\n",
    "        #self.show_loading()\n",
    "        #QTimer.singleShot(3000, self.hide_loading)  # Cache l'animation après 3s\n",
    "    def update_theme_icon(self):\n",
    "        current = USER_PREFERENCES.get(\"theme\", \"light\")\n",
    "        icon = \"🌞\" if current == \"light\" else \"🌙\"\n",
    "        self.theme_toggle_button.setText(icon)\n",
    "\n",
    "    def apply_custom_button_style(self):\n",
    "        style = \"\"\"\n",
    "        /* Bouton générique */\n",
    "        QPushButton {\n",
    "            border: none;\n",
    "            padding: 8px 14px;\n",
    "            border-radius: 6px;\n",
    "            font-size: 14px;\n",
    "            font-weight: bold;\n",
    "            min-width: 90px;\n",
    "        }\n",
    "\n",
    "        QPushButton:hover {\n",
    "            padding: 9px 15px;\n",
    "        }\n",
    "\n",
    "        /* Bouton Envoyer (Bleu) */\n",
    "        QPushButton#send_button {\n",
    "            background-color: #2196F3;\n",
    "            color: white;\n",
    "        }\n",
    "        QPushButton#send_button:hover {\n",
    "            background-color: #1976D2;\n",
    "        }\n",
    "        QPushButton#send_button:pressed {\n",
    "            background-color: #0D47A1;\n",
    "        }\n",
    "\n",
    "        /* Bouton Quitter (Rouge) */\n",
    "        QPushButton#quit_button {\n",
    "            background-color: #f44336;\n",
    "            color: white;\n",
    "        }\n",
    "        QPushButton#quit_button:hover {\n",
    "            background-color: #d32f2f;\n",
    "        }\n",
    "        QPushButton#quit_button:pressed {\n",
    "            background-color: #b71c1c;\n",
    "        }\n",
    "\n",
    "        /* Boutons du haut (Gris/bleu clair) */\n",
    "        QPushButton#load_button,\n",
    "        QPushButton#save_button,\n",
    "        summary_box.toggle_button {\n",
    "            background-color: #e0e0e0;\n",
    "            color: #333;\n",
    "        }\n",
    "        QPushButton#load_button:hover,\n",
    "        QPushButton#save_button:hover {\n",
    "            background-color: #bdbdbd;\n",
    "        }\n",
    "        QPushButton#load_button:pressed,\n",
    "        QPushButton#save_button:pressed {\n",
    "            background-color: #9e9e9e;\n",
    "        }\n",
    "        \"\"\"\n",
    "        self.setStyleSheet(self.styleSheet() + style)\n",
    "\n",
    "    def apply_theme(self):\n",
    "        theme_name = USER_PREFERENCES.get(\"theme\", \"clair\")\n",
    "        qss_path = os.path.join(os.path.dirname(__file__), f\"{theme_name}_theme.css\")\n",
    "\n",
    "        try:\n",
    "            with open(qss_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                qss = f.read()\n",
    "                self.setStyleSheet(qss)\n",
    "                print(f\"🎨 Thème appliqué : {theme_name}\")\n",
    "                self.apply_custom_button_style()  # ✅ Applique ton style bouton APRÈS\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Erreur chargement thème '{theme_name}':\", e)\n",
    "\n",
    "    def toggle_theme(self):\n",
    "        current = USER_PREFERENCES.get(\"theme\", \"light\")\n",
    "        USER_PREFERENCES[\"theme\"] = \"dark\" if current == \"light\" else \"light\"\n",
    "        self.apply_theme()\n",
    "        self.update_theme_icon()\n",
    "\n",
    "    \n",
    "    def _open_history_file(self):\n",
    "        file_path, _ = QFileDialog.getOpenFileName(self, \"Charger un historique\", \"\", \"Fichiers JSON (*.json)\")\n",
    "        if file_path:\n",
    "            self.controller.load_history_from_file(file_path)\n",
    "    def fade_in_widget(self, widget, duration=800):\n",
    "        widget.setVisible(True) \n",
    "        effect = QGraphicsOpacityEffect(widget)\n",
    "        widget.setGraphicsEffect(effect)\n",
    "\n",
    "        animation = QPropertyAnimation(effect, b\"opacity\", widget)\n",
    "        animation.setDuration(duration)\n",
    "        animation.setStartValue(0.0)\n",
    "        animation.setEndValue(1.0)\n",
    "        animation.start()\n",
    "\n",
    "        # 🔐 Stockage fort (pas juste une propriété du widget) pour éviter la suppression\n",
    "        self._active_animations.append(animation)\n",
    "\n",
    "        # 🔁 Nettoyage automatique une fois l'animation terminée\n",
    "        animation.finished.connect(lambda: self._active_animations.remove(animation))\n",
    "\n",
    "\n",
    "    def _slide_and_fade_in(self, widget, duration=800):\n",
    "        #widget.setVisible(True)\n",
    "        widget.adjustSize()  # 🔧 important pour bien récupérer sizeHint()\n",
    "\n",
    "        full_height = widget.sizeHint().height()\n",
    "\n",
    "        effect = QGraphicsOpacityEffect(widget)\n",
    "        widget.setGraphicsEffect(effect)\n",
    "\n",
    "        fade = QPropertyAnimation(effect, b\"opacity\", widget)\n",
    "        fade.setDuration(duration)\n",
    "        fade.setStartValue(0.0)\n",
    "        fade.setEndValue(1.0)\n",
    "\n",
    "        widget.setMaximumHeight(0)  # 🧨 réduit à 0 pour slider depuis rien\n",
    "\n",
    "        slide = QPropertyAnimation(widget, b\"maximumHeight\", widget)\n",
    "        slide.setDuration(duration)\n",
    "        slide.setStartValue(0)\n",
    "        slide.setEndValue(full_height)\n",
    "        slide.setEasingCurve(QEasingCurve.OutCubic)\n",
    "\n",
    "        group = QParallelAnimationGroup()\n",
    "        group.addAnimation(fade)\n",
    "        group.addAnimation(slide)\n",
    "\n",
    "        # 🔐 Sauvegarde pour ne pas garbage collect l’anim\n",
    "        if not hasattr(self, \"_active_animations\"):\n",
    "            self._active_animations = []\n",
    "        self._active_animations.append(group)\n",
    "\n",
    "        def _on_finished():\n",
    "            widget.setMaximumHeight(16777215)  # 🔓 Qt max height\n",
    "            self._active_animations.remove(group)\n",
    "\n",
    "        group.finished.connect(_on_finished)\n",
    "        group.start()\n",
    "    def _create_chat_bubble(self, icon_path, html_text):\n",
    "\n",
    "        container = QWidget()\n",
    "        layout = QHBoxLayout(container)\n",
    "        layout.setContentsMargins(5, 5, 5, 5)\n",
    "        layout.setSpacing(10)\n",
    "\n",
    "        # 🖼️ Icône à gauche\n",
    "        icon_label = QLabel()\n",
    "        icon_pixmap = QPixmap(icon_path)\n",
    "        if not icon_pixmap.isNull():\n",
    "            icon_label.setPixmap(icon_pixmap.scaled(32, 32, Qt.KeepAspectRatio, Qt.SmoothTransformation))\n",
    "        icon_label.setFixedSize(36, 36)\n",
    "        icon_label.setStyleSheet(\"background-color: #E0F7FA; border-radius: 6px; padding: 2px;\")\n",
    "        layout.addWidget(icon_label)\n",
    "\n",
    "        # 🗨️ Bulle de texte\n",
    "        bubble = QLabel(html_text)\n",
    "        bubble.setTextFormat(Qt.TextFormat.RichText)\n",
    "        bubble.setWordWrap(True)\n",
    "        bubble.setTextInteractionFlags(Qt.TextSelectableByMouse)  # texte sélectionnable\n",
    "        theme = USER_PREFERENCES.get(\"theme\", \"light\")\n",
    "        bg = \"#FFFFFF\" if theme == \"light\" else \"#2c2c2c\"\n",
    "        fg = \"#000000\" if theme == \"light\" else \"#eeeeee\"\n",
    "\n",
    "        bubble.setStyleSheet(f\"\"\"\n",
    "            QLabel {{\n",
    "                background-color: {bg};\n",
    "                color: {fg};\n",
    "                border-radius: 8px;\n",
    "                padding: 8px;\n",
    "                font-size: 13px;\n",
    "            }}\n",
    "        \"\"\")\n",
    "\n",
    "        bubble.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Minimum)\n",
    "        layout.addWidget(bubble, 1)\n",
    "\n",
    "        return container\n",
    "\n",
    "\n",
    "\n",
    "    # Fonction pour ajouter un message à la zone d'affichage du chat\n",
    "    def append_message(self, sender, content):\n",
    "        user_icon = os.path.join(os.path.dirname(__file__), \"assets\", \"user_icon.png\")\n",
    "        bubble = self._create_chat_bubble(user_icon, f\"<b>{sender}:</b> {content}\")\n",
    "        self.chat_layout.addWidget(bubble)\n",
    "        self.fade_in_widget(bubble)\n",
    "        QTimer.singleShot(100, lambda: self.chat_scroll.verticalScrollBar().setValue(\n",
    "            self.chat_scroll.verticalScrollBar().maximum()))\n",
    "\n",
    "    \"\"\" def append_message(self, sender, content):\n",
    "        label = QLabel(f\"<b>{sender}:</b> {content}\")\n",
    "        label.setTextFormat(Qt.TextFormat.RichText)\n",
    "        label.setWordWrap(True)\n",
    "        label.setStyleSheet(\"padding: 6px;\")\n",
    "        self.chat_layout.addWidget(label)\n",
    "\n",
    "        self.fade_in_widget(label)\n",
    "        QTimer.singleShot(100, lambda: self.chat_scroll.verticalScrollBar().setValue(\n",
    "            self.chat_scroll.verticalScrollBar().maximum())) \"\"\"\n",
    "\n",
    "    # Fonction pour afficher un message de chargement\n",
    "    def show_loading(self):\n",
    "        self.dots_state = 0\n",
    "        self.loading_text_label.setText(\"Réflexion en cours\")\n",
    "        self.loading_widget.setVisible(True)\n",
    "        self.loading_movie.start()\n",
    "        self.dots_timer.start(500)  # Rafraîchissement toutes les 500ms\n",
    "        QApplication.processEvents()\n",
    "    # Fonction pour cacher le message de chargement\n",
    "    def hide_loading(self):\n",
    "        self.dots_timer.stop()\n",
    "        self.loading_movie.stop()\n",
    "        self.loading_widget.setVisible(False)\n",
    "        QApplication.processEvents()\n",
    "    # Fonction pour animer le texte de chargement\n",
    "    def _animate_loading_text(self):\n",
    "        dots = '.' * (self.dots_state % 4)  # \"\", \".\", \"..\", \"...\"\n",
    "        self.loading_text_label.setText(f\"Réflexion en cours{dots}\")\n",
    "        self.dots_state += 1\n",
    "    # Fonction pour afficher la réponse de l'assistant\n",
    "    def display_response(self, markdown_text):\n",
    "        html = markdown2.markdown(markdown_text)\n",
    "\n",
    "        # 🔎 Vérifie si c'est du HTML complexe (tableau, div, etc.)\n",
    "        if \"<table\" in html or \"<div\" in html:\n",
    "            browser = QTextBrowser()\n",
    "            browser.setHtml(f\"<b>Assistant:</b><br>{html}\")\n",
    "            browser.setOpenExternalLinks(True)\n",
    "            browser.setStyleSheet(\"\"\"\n",
    "                QTextBrowser {\n",
    "                    background-color: #1e1e1e;\n",
    "                    color: white;\n",
    "                    border: none;\n",
    "                    padding: 6px;\n",
    "                    border-radius: 6px;\n",
    "                }\n",
    "            \"\"\")\n",
    "            content_widget = browser\n",
    "        else:\n",
    "            label = QLabel(f\"<b>Assistant:</b> {html}\")\n",
    "            label.setTextFormat(Qt.TextFormat.RichText)\n",
    "            label.setWordWrap(True)\n",
    "            theme = USER_PREFERENCES.get(\"theme\", \"light\")\n",
    "            text_color = \"#333\" if theme == \"light\" else \"#eeeeee\"\n",
    "\n",
    "            label.setStyleSheet(f\"\"\"\n",
    "                QLabel {{\n",
    "                    padding: 6px;\n",
    "                    color: {text_color};\n",
    "                }}\n",
    "            \"\"\")\n",
    "\n",
    "            content_widget = label\n",
    "\n",
    "        # 💬 Crée une bulle avec icône\n",
    "        icon_path = os.path.join(os.path.dirname(__file__), \"assets\", \"robot_icon.png\")\n",
    "        bubble = self._create_chat_bubble(icon_path, f\"<b>Assistant:</b> {html}\")\n",
    "        self.chat_layout.addWidget(bubble)\n",
    "        self.fade_in_widget(bubble)\n",
    "\n",
    "        # ⬇️ Scroll vers le bas\n",
    "        QTimer.singleShot(100, lambda: self.chat_scroll.verticalScrollBar().setValue(\n",
    "            self.chat_scroll.verticalScrollBar().maximum()))\n",
    "    # Fonction pour le résumé \n",
    "    def append_collapsible_summary(self, html_summary: str):\n",
    "        if self.summary_box is None:\n",
    "            self.summary_box = CollapsibleBox(\"📊 Résumé\")\n",
    "\n",
    "            label = QLabel()\n",
    "            label.setTextFormat(Qt.TextFormat.RichText)\n",
    "            label.setWordWrap(True)\n",
    "            label.setTextInteractionFlags(Qt.TextSelectableByMouse)\n",
    "            label.setText(html_summary)\n",
    "\n",
    "            scroll = QScrollArea()\n",
    "            scroll.setWidgetResizable(True)\n",
    "            scroll.setStyleSheet(\"QScrollArea { border: none; }\")\n",
    "            scroll.setWidget(label)\n",
    "\n",
    "            # ⬇️ Emballage dans un frame (fixe le problème de layout durant l’anim)\n",
    "            wrapper = QFrame()\n",
    "            layout = QVBoxLayout()\n",
    "            layout.setContentsMargins(0, 0, 0, 0)\n",
    "            layout.addWidget(scroll)\n",
    "            wrapper.setLayout(layout)\n",
    "\n",
    "            self.summary_box.setContent(wrapper)\n",
    "            self.layout.insertWidget(self.layout.count() - 2, self.summary_box)\n",
    "\n",
    "            QTimer.singleShot(0, lambda: self._slide_and_fade_in(self.summary_box))  # ⬅️ Animation ici\n",
    "        else:\n",
    "            scroll = self.summary_box.content_area.layout().itemAt(0).widget().layout().itemAt(0).widget()\n",
    "            label = scroll.widget()\n",
    "            label.setText(html_summary)\n",
    "\n",
    "        self.summary_box.content_area.setVisible(True)\n",
    "        self.summary_box.toggle_button.setChecked(True)\n",
    "        self.summary_box.toggle_button.setArrowType(Qt.DownArrow)\n",
    "\n",
    "    def set_controller(self, controller):\n",
    "        self.controller = controller  # accès au contrôleur depuis la vue\n",
    "\n",
    "    def showEvent(self, event):\n",
    "        super().showEvent(event)\n",
    "\n",
    "        # Appelle une fonction d’accueil une seule fois\n",
    "        if not hasattr(self, \"_welcome_done\"):\n",
    "            self.controller.display_welcome_message()\n",
    "            self._welcome_done = True\n",
    "\n",
    "    def append_matplotlib_plot(self, fig):\n",
    "        canvas = FigureCanvas(fig)\n",
    "        canvas.setMinimumHeight(300)  # Tu peux ajuster\n",
    "\n",
    "        # Option simple sans box repliable:\n",
    "        #self.layout.insertWidget(self.layout.count() - 2, canvas)\n",
    "\n",
    "        # dans une box repliable\n",
    "        scroll_area = QScrollArea()\n",
    "        scroll_area.setWidget(canvas)\n",
    "        scroll_area.setWidgetResizable(True)\n",
    "        scroll_area.setHorizontalScrollBarPolicy(Qt.ScrollBarAsNeeded)\n",
    "        scroll_area.setVerticalScrollBarPolicy(Qt.ScrollBarAsNeeded)\n",
    "        box = CollapsibleBox(\"📈 Graphique généré\")\n",
    "        box.setContent(scroll_area)\n",
    "        self.layout.insertWidget(self.layout.count() - 2, box)\n",
    "    @Slot()\n",
    "    def update_after_response(self):\n",
    "        try:\n",
    "            summary = self.controller._format_summary(self.controller.state)\n",
    "            self.append_collapsible_summary(summary)\n",
    "        except Exception as e:\n",
    "            print(\"Erreur dans le résumé:\", e)\n",
    "\n",
    "        # 🎯 Affiche le graphique si présent\n",
    "        fig = self.controller.state.get(\"figure\")\n",
    "        if fig:\n",
    "            self.display_response(\"📈 Voici le graphique généré à partir des données sélectionnées.\")\n",
    "            self.append_matplotlib_plot(fig)\n",
    "        else:\n",
    "            # S’il n’y a pas de figure, affiche le message AI normal\n",
    "            last = self.controller.history[-1]\n",
    "            if isinstance(last, AIMessage):\n",
    "                self.display_response(last.content)\n",
    "\n",
    "        self.hide_loading()\n",
    "\n",
    "\n",
    "    @Slot(str)\n",
    "    def display_error(self, error_msg):\n",
    "        self.append_message(\"Erreur\", error_msg)\n",
    "        self.hide_loading()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6547b139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PySide6.QtCore import QObject, Signal\n",
    "from langchain_core.messages import HumanMessage\n",
    "from index import chat_with_human_graph\n",
    "\n",
    "class Worker(QObject):\n",
    "    finished = Signal(object, object)  # history, state\n",
    "    error = Signal(str)\n",
    "\n",
    "    def __init__(self, history, user_text):\n",
    "        super().__init__()\n",
    "        self.history = history\n",
    "        self.user_text = user_text\n",
    "\n",
    "    def run(self):\n",
    "        try:\n",
    "            messages = list(self.history) + [HumanMessage(content=self.user_text)]\n",
    "            state = {\n",
    "                \"messages\": messages,\n",
    "                \"order\": [],\n",
    "                \"question\": [],\n",
    "                \"tools_to_answer\": [],\n",
    "                \"finished\": False,\n",
    "                \"Trois\": False,\n",
    "                \"request_call\": None,  # Assurez-vous que request_call est initialisé\n",
    "                \"request_call_initial\": None,  # Assurez-vous que request_call_initial est initialisé\n",
    "                \"traitement_format\": None,  # Assurez-vous que traitement_format est initialisé\n",
    "                \"dataFrames\": [],  # Assurez-vous que dataFrames est initialisé\n",
    "                \"input_tokens\" : 0,\n",
    "                \"output_tokens\" : 0,\n",
    "                \"prix_input_tokens\" : 0,\n",
    "                \"prix_output_tokens\" : 0\n",
    "            }\n",
    "            result = chat_with_human_graph.invoke(state, config={\"recursion_limit\": 100})\n",
    "            new_history = result[\"messages\"]\n",
    "            \n",
    "            # ✅ Astuce sécurité : pas d’objet Qt dans le state retourné\n",
    "            state_copy = dict(result)\n",
    "            self.finished.emit(new_history, state_copy)\n",
    "        except Exception as e:\n",
    "            self.error.emit(str(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851d30e6",
   "metadata": {},
   "source": [
    "Etat des données entre chaque agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9a2a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List, TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "from Tools_nodes.treatment_node.traitement_format import Traitement_Format\n",
    "\n",
    "from Graph_Agents.ExtractDocsAgent.request_format import request \n",
    "from matplotlib.figure import Figure\n",
    "class OrderState(TypedDict):\n",
    "    \"\"\"State representing the customer's order conversation.\"\"\"\n",
    "\n",
    "    # The chat conversation. This preserves the conversation history\n",
    "    # between nodes. The `add_messages` annotation indicates to LangGraph\n",
    "    # that state is updated by appending returned messages, not replacing\n",
    "    # them.\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "    #Question posée par l'utilisateur\n",
    "    question : str\n",
    "\n",
    "    #Indique l'information cherchée\n",
    "    information_chercher : str\n",
    "    #Indique les traitements à effectuer sur l'information cherchée\n",
    "    traitements : List[str]\n",
    "    #Indique le traitement actuel sur l'information cherchée\n",
    "    traitement : str\n",
    "    i : int\n",
    "\n",
    "    #Requête obtenue pour en envoyer une à la base de donnée\n",
    "    request_call : Annotated[request, 'Contient les requêtes']\n",
    "    # request_call avant l'agent generateur\n",
    "    request_call_initial: Annotated[request, 'Contient les requêtes avant l\\'agent generateur']\n",
    "    #DataFrame obtenu et traité à partir de la baes de donnée et dont le contenu\n",
    "    #est envoyé à l'utilisateur\n",
    "    dataFrames : list\n",
    "\n",
    "    # Flag indicating that the order is placed and completed.\n",
    "    finished: bool\n",
    "    # Traitement formaté pour l'affichage\n",
    "    traitement_format: Traitement_Format\n",
    "    # Matplotlib figure to be displayed in the UI\n",
    "    figure: Figure\n",
    "\n",
    "    input_tokens : int\n",
    "    output_tokens : int\n",
    "    latest_input_tokens: int\n",
    "    latest_output_tokens: int\n",
    "\n",
    "    prix_input_tokens : float\n",
    "    prix_output_tokens : float\n",
    "    Huron_related: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438f3a6f",
   "metadata": {},
   "source": [
    "Création du graphe d'agents intéragissant entre eux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc0f7e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langgraph.graph import StateGraph, START, MessagesState\n",
    "\n",
    "from Graph_Agents.human_node import human_node, maybe_exit_human_node\n",
    "from Graph_Agents.CreateurTache.CreateurTache import CreateurTache\n",
    "from Graph_Agents.CreateurTache.Separation import Separation\n",
    "from Graph_Agents.Sigscan.Agents.Agents.formaliseur_requete import Formalisateur_requete\n",
    "from Graph_Agents.Sigscan.Agents.Agents.prompt import PROMPT\n",
    "from Graph_Agents.Sigscan.BDD.interactionBdd import InteractionBdd\n",
    "from Graph_Agents.Sigscan.Requetes.Requetes.objects import Objet\n",
    "from Graph_Agents.Sigscan.Requetes.Requetes.areas import Area\n",
    "from Tools_nodes.database_node.database_node import database_agent\n",
    "from Tools_nodes.continuer_node.continuer_node import Continuer_node\n",
    "from Graph_Agents.TreatmentAgent.treatmentAgent import TreatmentAgent\n",
    "from Graph_Agents.TreatmentAgent.prompt_treatmentAgent import AGENT_GENERATION_SYSINT, EXEMPLES\n",
    "from Tools_nodes.treatment_node.treatment_node import treatment_node\n",
    "from Graph_Agents.TrieurQuestion.Trieur_question_agent import Trieur_question_agent\n",
    "from Tools_nodes.trieur_node.trieur_node import Trieur_node\n",
    "from Graph_Agents.TrieurQuestion.OutputSchema import OutputSchema\n",
    "from Graph_Agents.ExtractDocsAgent.Extract_docs_agent import Extract_docs_agent\n",
    "\n",
    "from Graph_Agents.GenerateurAgent.generateur_agent import Generateur_agent, Choix\n",
    "from Tools_nodes.generateur_node.generateur_node import generateur_node\n",
    "\n",
    "from Tools_nodes.treatment_node.traitement_format import fonction\n",
    "\n",
    "from OrderState import OrderState\n",
    "\n",
    "createurTache = CreateurTache(Separation)\n",
    "continuer_node = Continuer_node()\n",
    "generer_reponse = Generateur_agent(Choix)\n",
    "treatmentAgent = TreatmentAgent(fonction, AGENT_GENERATION_SYSINT, EXEMPLES)\n",
    "extract_doc_agent = Extract_docs_agent()\n",
    "trieur_question = Trieur_question_agent(OutputSchema)\n",
    "trieur_node = Trieur_node()\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"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\" #Enlever ensuite\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"My_project\"\n",
    "formalisateur_requete = Formalisateur_requete(prompt_debut=PROMPT, objets=Objet, areas=Area)\n",
    "interactionBdd = InteractionBdd()\n",
    "# Start building a new graph.\n",
    "graph_builder = StateGraph(OrderState)\n",
    "\n",
    "# Add the chatbot and human nodes to the app graph.\n",
    "#graph_builder.add_node(\"chatbot\", chatbot_with_welcome_msg)\n",
    "graph_builder.add_node(\"Humain\", human_node)\n",
    "graph_builder.add_node(\"Trieur de questions\", trieur_question.interaction)\n",
    "graph_builder.add_node(\"Créateur de tâches\", createurTache.interaction)\n",
    "graph_builder.add_node(\"Formulateur de demandes d'informations\", extract_doc_agent.interaction)\n",
    "graph_builder.add_node(\"Executeur de demandes d'informations\", database_agent)\n",
    "graph_builder.add_node(\"Formulateur de requêtes de traitement\", treatmentAgent.interaction)\n",
    "graph_builder.add_node(\"Indicateur de l'existance de traitements supplémentaires\", continuer_node.continuer_node)\n",
    "graph_builder.add_node(\"Executeur de requêtes de traitement\", treatment_node)\n",
    "\n",
    "graph_builder.add_node(\"Générateur de réponse\", generer_reponse.interaction)\n",
    "graph_builder.add_node(\"Application du générateur\", generateur_node)\n",
    "\n",
    "graph_builder.add_node(\"Formalisateur de requête\", formalisateur_requete.formaliser_requete)\n",
    "graph_builder.add_node(\"Interaction à la base de donnée\", interactionBdd.interactionBdd)\n",
    "\n",
    "# The chatbot will always go to the human next.\n",
    "\n",
    "graph_builder.add_conditional_edges(\"Humain\", maybe_exit_human_node)\n",
    "graph_builder.add_conditional_edges(\"Indicateur de l'existance de traitements supplémentaires\", continuer_node.maybe_route_to_treatment)\n",
    "graph_builder.add_conditional_edges(\"Trieur de questions\", trieur_node.sigscan_or_huron)\n",
    "# pour sigscan\n",
    "graph_builder.add_edge(\"Formalisateur de requête\", \"Interaction à la base de donnée\")\n",
    "graph_builder.add_edge(\"Interaction à la base de donnée\", \"Humain\")\n",
    "#pour huron\n",
    "graph_builder.add_edge(\"Créateur de tâches\", \"Formulateur de demandes d'informations\")\n",
    "graph_builder.add_edge(\"Formulateur de demandes d'informations\", \"Executeur de demandes d'informations\")\n",
    "graph_builder.add_edge(\"Executeur de demandes d'informations\", \"Indicateur de l'existance de traitements supplémentaires\")\n",
    "graph_builder.add_edge(\"Formulateur de requêtes de traitement\", \"Executeur de requêtes de traitement\")\n",
    "graph_builder.add_edge(\"Executeur de requêtes de traitement\", \"Indicateur de l'existance de traitements supplémentaires\")\n",
    "\n",
    "graph_builder.add_edge(\"Générateur de réponse\", \"Application du générateur\")\n",
    "graph_builder.add_edge(\"Application du générateur\", \"Humain\")\n",
    "\n",
    "# Start with the chatbot again.\n",
    "graph_builder.add_edge(START, \"Humain\")\n",
    "\n",
    "chat_with_human_graph = graph_builder.compile()\n",
    "\n",
    "# The default recursion limit for traversing nodes is 25 - setting it higher means\n",
    "# you can try a more complex order with multiple steps and round-trips (and you\n",
    "# can chat for longer!)\n",
    "config = {\"recursion_limit\": 100}\n",
    "\n",
    "# Remember that this will loop forever, unless you input `q`, `quit` or one of the\n",
    "# other exit terms defined in `human_node`.\n",
    "# Uncomment this line to execute the graph:\n",
    "#state = chat_with_human_graph.invoke({\"messages\": []}, config)\n",
    "if __name__ == \"__main__\":\n",
    "    # Pour tester le graphe manuellement (utile en dev)\n",
    "    state = {\"messages\": []}\n",
    "    result = chat_with_human_graph.invoke(state, config={\"recursion_limit\": 100})\n",
    "# Things to try:\n",
    "#  - Just chat! There's no ordering or menu yet.\n",
    "#  - 'q' to exit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e3bf610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎨 Thème appliqué : dark\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gregory\\Documents\\GitHub\\ia-assistant-supervision-industrielle\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3680: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from PySide6.QtWidgets import QApplication\n",
    "from ui.view import ChatWindow\n",
    "from ui.controller import ChatController\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = QApplication(sys.argv)\n",
    "    \n",
    "    controller = ChatController()\n",
    "    view = ChatWindow(controller)\n",
    "    controller.view = view\n",
    "    view.show()\n",
    "    sys.exit(app.exec())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
