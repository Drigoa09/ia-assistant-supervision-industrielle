from index import chat_with_human_graph
from langchain_core.messages import HumanMessage
def process_user_input(history, user_text):
    messages = list(history) + [HumanMessage(content=user_text)]
    state = {
        "messages": messages,
        "order": [],
        "question": user_text,
        "tools_to_answer": [],
        "finished": False,
        "Trois": False
    }
    print(">> input to agent:", messages)

    result = chat_with_human_graph.invoke(state, config={"recursion_limit": 100})

    # On prÃ©pare le rÃ©sultat final
    updated_state = result

    # ğŸ” Ajout de la requÃªte d'origine si elle a Ã©tÃ© extraite
    if "request_call" not in result:
        print("âš ï¸ Aucune 'request_call' trouvÃ©e dans le rÃ©sultat.")
    else:
        print("âœ… 'request_call' dÃ©tectÃ©.")

    return {
        "messages": result["messages"],
        "state": updated_state
    }
